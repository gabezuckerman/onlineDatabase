---
title: "How to add and download raw data"
author: "Gabe Zuckerman"
date: "1/20/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
library(data.table)
library(tidyverse)
library(rmarkdown)
library(lubridate)

```

# Relational database architechure

In the box folder the raw data is roughly stored in this format:

![](puma_db_graph.png)

To add data, you need to format the data to match the 4 leftmost tables.  When formatting, it is okay if you don't have information for all the columns, so long as the information you do have exactly matches the format the data is already in.

# Manually create the following 4 tables with the appropriate using your data on your own computer

Unfortunately, due to the variety of formats we have recieved data in, we have to go through this arduous process to ensure all the elk data is standardize. This is time consuming, sorry. Once you have created them, follow the steps in the "Now that you've formatted your data..." section

## 1.) the animals table

#### Necesary columns: `animals_code`, `herd`, and `data_source`

The animals table is formatted like this (used the arrows to see additional rows and columns):


```{r animals, layout="l-body-outset"}
head(fread("newDatabaseFiles/animals.csv"), 20) %>% paged_table(options = list(cols.print = 5))
```

##### Column definitions

`animals_code`: unique animal identifier

`name`: unnecessary column, leave it as `NA` 

`sex`: if you have it, leave it as `NA` otherwise

`age`: if you have it, leave it as `NA` otherwise

`species_code`: put a 1 for elk; leftover from when there were multiple species

`herd`: duh

`capture_site`: if you have it, leave it as `NA` otherwise

`data_source`: this is very important, make sure to add it

`note`: if there is anything else we need to know about the animal

`insert_timestamp`: just use now() function when creating the column, good to know for version control's sake

`commonHerd`: leave as herd, unless the herd is a subset of another herd

`coreGYE`: herds used in Gigliotti et al. 2021, generally herds that migrate into Yellowstone. YES/NO

`Fed`: does this herd have access to feedgrounds YES/NO



##### Helpful code/tips to create this table

Generally, this table is pretty straight forward to make. I tend to select the columns from the data I have, taking only one row per individual, and renaming columns as necessary. Once I have this table I just use `$` to create the remaining columns that are generally `NA` or one value for the entire table. Make sure the columns are in the same order as the template.

## 2.) the sensors table

#### Necesary column: `gps_sensors_code` 

The sensors table is formatted like this (used the arrows to see additional rows and columns):


```{r sensors, layout="l-body-outset"}
head(fread("newDatabaseFiles/sensors.csv"), 20) %>% paged_table(options = list(cols.print = 5))
```


##### Column definitions

`gps_sensors_code`: unique gps collar identifier

`purchase_date`: if you have it, leave it as `NA` otherwise

`frequency`: if you have it, leave it as `NA` otherwise

`vendor`: if you have it, leave it as `NA` otherwise

`model`: if you have it, leave it as `NA` otherwise

`sim`: unnecessary, leave it as `NA`

`insert_timestamp`: just use now() function when creating the column, good to know for version control's sake

##### Helpful code/tips to create this table

Generally, this table is pretty straight forward to make. I tend to select the columns from the data I have, taking only one row per individual, and renaming columns as necessary. Once I have this table I just use `$` to create the remaining columns that are generally `NA` or one value for the entire table. Make sure the columns are in the same order as the template. 

## 3.) the sensors-animals table

#### Necesary columns: `gps_sensors_animals_id`, `animals_code`, `gps_sensors_code`, `start_time` and `end_time`

The sensors-animals table is formatted like this (used the arrows to see additional rows and columns):


```{r sensAni, layout="l-body-outset"}
head(fread("newDatabaseFiles/sensorsAnimals.csv"), 20) %>% paged_table(options = list(cols.print = 5))
```

##### Column definitions

`gps_sensors_animals_id`: main identifier combining both the animal and collar. When you are creating this table, leave it as `NA`. It will start from where the current database leaves off (the code below automatically takes care of this).

`animals_code`: see above

`gps_sensors_code`: see above

`start_time`: collar deployment date, in ymd_hms format

`end_time`: `NA` if ongoing, otherwise put the date the collar was removed or fell off, in ymd_hms format

`status`: "inactive" if `end_time` is earlier than present date, otherwise "active"

`notes`: anything else important to know

`insert_timestamp`: just use now() function when creating the column, good to know for version control's sake

##### Helpful code/tips to create this table

If you have clean gps data, you can run the following to generate start and end dates

`data %>% group_by(animals_code, gps_sensors_code) %>% dplyr::summarise(start_time = min(datetime), end_time = max(datetime))`
 
then you can easily add the other columns by selecting the columns from your data, taking only one row per individual, and renaming columns as necessary. Once you have this table,  use `$` to create the remaining columns that are generally `NA` or one value for the entire table. Make sure the columns are in the same order as the template.

## 4.) the GPS table

#### Necesary columns: `gps_sensors_code`, `latitude`, `longitude`, and `acquisition_time`

The GPS table is formatted like this (used the arrows to see additional rows and columns):


```{r gps, layout="l-body-outset"}
head(fread("newDatabaseFiles/gpsSubset.csv"), 20) %>% paged_table(options = list(cols.print = 5))
```

Only include successfully GPS fixes.

`device_name`: leave as `NA`

`gps_sensors_code`: see above

`line_no`: leave as `NA`

`utc_date_time`: add/subtract the appropriate number of hours based on the timezone

`lmt_date_time`: your datetime

`latitude`: make sure your data is in EPSG 4326

`longitude`: make sure your data is in EPSG 4326

`altitude `: add if you have it, otherwise `NA`

`fix_status': add if you have it, otherwise `NA`

`dop`: dilution of precision, add if you have it, otherwise `NA`

`tempc`: temperature in degrees Celsius, add if you have it, otherwise `NA`

`main_volt`: add if you have it, otherwise `NA`

`back_volt`: add if you have it, otherwise `NA`

`insert_timestamp`: just use now() function when creating the column, good to know for version control's sake

`acquisition_time`: your datetime

##### Helpful code/tips to create this table

I tend to select the columns from the data I have, renaming columns as necessary. Once I have this table I just use `$` to create the remaining columns that are generally `NA` or one value for the entire table. This one has a bunch of columns, so make sure they are in the same order as the template.

# Now that you've formatted your data...

## 1.) download the most recent copy of the database (all 4 files)

these are the 4 files in `data/movement data/GYElk/raw` folder on box

## 2.) run the following:

All of this step is to be completed on your own machine.

```{r add your data, eval = F, echo = T}
library(data.table)
library(tidyverse)

#make sure to adjust your working directory as necessary. 

#these are the files from the database
animalsCurrent <- fread("animals.csv")
sensorsCurrent <- fread("sensors.csv")
sensAniCurrent <- fread("sensorsAnimals.csv")
gpsCurrent <- fread("gps.csv")

#replace the tables in all caps with the names of the tables you just created above
newANIMALS <- rbind(animalsCurrent, YOURANIMALSTABLE)
newSENSORS <- rbind(sensorsCurrent, YOURSENSORSTABLE)
#before creating the new sensAni, we need to generate ids that begin where the current database leaves off
startingID <- max(sensAniCurrent$gps_sensors_animals_id) + 1
YOURSENSANITABLE$gps_sensors_animals_id <- seq(startingID, startingID + nrow(YOURSENSANITABLE))
#now you can bind the two tables together
newSENSANI <- rbind(sensAniCurrent, YOURSENSANITABLE)

newGPS <- rbind(gpsCurrent, YOURGPSTABLE)

#save the new files locally, then add to box in step 3
fwrite(newANIMALS, "animals.csv")
fwrite(newSENSORS, "sensors.csv")
fwrite(newSENSANI, "sensorsAnimals.csv")
fwrite(newGPS, "gps.csv")
```

## 3.) Drag your new updated files into the `data/movement data/GYElk/raw` folder on box.

Box automatically has version control, so it should store the past ~20 or so versions of the database, in case any mistakes are made.

# If you need to download raw data...

#### Use the following code to leverage the database architechture to create the gps_data_animals table

First, download the the 4 files from `data/movement data/GYElk/raw` and place them in your working directory.

```{r download raw data, eval = F, echo = T}

#taking relevant columns from sensorsAnimals and animals
sensAniCols <- sensorsAnimals %>% dplyr::select(gps_sensors_animals_id, animals_code, gps_sensors_code)
aniCols <- animals %>% dplyr::select(animals_code, herd, commonHerd, coreGYE, Fed)

#merging by animals_code, should be one row per deployment
infoCols <- merge(sensAniCols, aniCols)

#taking relevant columns from gps data
gpsCols <- gps %>% dplyr::select(gps_sensors_code, acquisition_time, latitude, longitude)

#merging by gps_sensors_code, should be one row per gps fix
gpsAnimalsData <- merge(infoCols, gpsCols, by = "gps_sensors_code", allow.cartesian=TRUE)

#now ensuring that each individuals data is between the proper start/end date
filterToDeployment <- function(id) {
  
  #gets movement data
  indivData <- gpsAnimalsData %>% filter(gps_sensors_animals_id == id)

  #deployment start and end dates
  start <- filter(sensorsAnimals, gps_sensors_animals_id == id)$start_time
  end <- filter(sensorsAnimals, gps_sensors_animals_id == id)$end_time
  
  #filters to within appropriate interval, handles the various time formats
  if (end != "") {
    return(indivData %>% filter(parse_date_time(acquisition_time, orders = c("mdy_HM", "mdy", "ymd_HMS", "ymd")) >= parse_date_time(start, orders = c("mdy_HM", "mdy", "ymd_HMS", "ymd"))) %>% 
             filter(parse_date_time(acquisition_time, orders = c("mdy_HM", "mdy", "ymd_HMS", "ymd")) <= parse_date_time(end, c("mdy_HM", "mdy", "ymd_HMS", "ymd"))))
  } else {
    return(indivData %>% filter(parse_date_time(acquisition_time, orders = c("mdy_HM", "mdy", "ymd_HMS", "ymd")) >= parse_date_time(start, c("mdy_HM", "mdy", "ymd_HMS", "ymd"))))
  }
}

#may take a while, on my machine it took about 5 minutes
gpsAnimalsDataFiltered <- map_dfr(sensorsAnimals$gps_sensors_animals_id, filterToDeployment)


```
